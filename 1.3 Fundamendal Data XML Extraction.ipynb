{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML files cleaned!\n"
     ]
    }
   ],
   "source": [
    "stock_symbol = 'RELIANCE.NS'\n",
    "\n",
    "save_dir = f'{stock_symbol}_xml_files'\n",
    "xml_files = [os.path.join(save_dir, f) for f in os.listdir(save_dir) if f.endswith('.xml')]\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    # Finding the start line\n",
    "    start_index = next((i for i, line in enumerate(lines) if '<in-bse-fin:Symbol contextRef=\"OneD\">' in line), None)\n",
    "    if start_index is None:\n",
    "        print(f\"Warning: {xml_file} does not contain the start tag. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Slicing the lines to remove unnecessary parts and replacing 'in-bse-fin:'\n",
    "    cleaned_lines = [line.replace('in-bse-fin:', '') for line in lines[start_index:]]\n",
    "\n",
    "    # Writing back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "\n",
    "print(\"XML files cleaned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml_content(content):\n",
    "    # Find the first opening tag and last closing tag\n",
    "    first_tag = content.find('<')\n",
    "    last_tag = content.rfind('>')\n",
    "\n",
    "    # Return the content between those indices\n",
    "    return content[first_tag:last_tag + 1]\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    cleaned_content = clean_xml_content(content)\n",
    "    \n",
    "    # Overwrite the original XML file with cleaned content\n",
    "    with open(xml_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(cleaned_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed contextRef attributes from XML files!\n"
     ]
    }
   ],
   "source": [
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Removing contextRef attributes using regex\n",
    "    cleaned_content = re.sub(r' contextRef=\"[^\"]*\"', '', content)\n",
    "    \n",
    "\n",
    "    # Writing back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.write(cleaned_content)\n",
    "\n",
    "print(\"Removed contextRef attributes from XML files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed contextRef attributes from XML files!\n"
     ]
    }
   ],
   "source": [
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Removing contextRef attributes using regex\n",
    "    cleaned_content = re.sub(r' unitRef=\"[^\"]*\"', '', content)\n",
    "    \n",
    "\n",
    "    # Writing back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.write(cleaned_content)\n",
    "\n",
    "print(\"Removed contextRef attributes from XML files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed contextRef attributes from XML files!\n"
     ]
    }
   ],
   "source": [
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Removing contextRef attributes using regex\n",
    "    cleaned_content = re.sub(r' decimals=\"[^\"]*\"', '', content)\n",
    "    \n",
    "\n",
    "    # Writing back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.write(cleaned_content)\n",
    "\n",
    "print(\"Removed contextRef attributes from XML files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed </xbrli:xbrl> from all XML files.\n"
     ]
    }
   ],
   "source": [
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Removing the </xbrli:xbrl> string\n",
    "    content = content.replace('</xbrli:xbrl>', '')\n",
    "\n",
    "    # Writing the modified content back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(\"Removed </xbrli:xbrl> from all XML files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been cleaned.\n"
     ]
    }
   ],
   "source": [
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # 1. Removing all closing tags\n",
    "    content = re.sub(r'</[^>]+>', '', content)\n",
    "\n",
    "    # 2. Removing all leftover \"<\"\n",
    "    content = content.replace('<', '')\n",
    "\n",
    "    # 3. Replacing all \">\" with \" : \"\n",
    "    content = content.replace('>', ' : ')\n",
    "\n",
    "    # Writing the modified content back to the file\n",
    "    with open(xml_file, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "print(\"Files have been cleaned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list to store dictionaries with data from each XML file\n",
    "all_data = []\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open(xml_file, 'r') as file:\n",
    "        # Dictionary to store data for the current XML file\n",
    "        data_dict = {}\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            # Skip empty lines\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            # Split the line at the delimiter to get the key and the value\n",
    "            parts = line.split(\" : \")\n",
    "            if len(parts) == 2:  # Ensure that we have a key and a value\n",
    "                key, value = parts\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                data_dict[key] = value\n",
    "        all_data.append(data_dict)\n",
    "\n",
    "# Create a DataFrame using the list of dictionaries\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Optional: save the DataFrame to a CSV file\n",
    "# df.to_csv(\"combined_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[['DateOnWhichPriorIntimationOfTheMeetingForConsideringFinancialResultsWasInformedToTheExchange', 'DateOfStartOfReportingPeriod', 'DateOfEndOfReportingPeriod', 'NatureOfReportStandaloneConsolidated', 'Income', 'DilutedEarningsLossPerShareFromContinuingAndDiscontinuedOperations', 'PaidUpValueOfEquityShareCapital', 'FaceValueOfEquityShareCapital']]\n",
    "final_df = final_df.rename(columns={\n",
    "    'DateOnWhichPriorIntimationOfTheMeetingForConsideringFinancialResultsWasInformedToTheExchange': 'Announcement Date',\n",
    "    'DateOfStartOfReportingPeriod': 'Start of Reporting Period',\n",
    "    'DateOfEndOfReportingPeriod': 'End of Reporting Period',\n",
    "    'NatureOfReportStandaloneConsolidated': 'Report Type',\n",
    "    'Income': 'Revenue',\n",
    "    'DilutedEarningsLossPerShareFromContinuingAndDiscontinuedOperations': 'EPS',\n",
    "    'PaidUpValueOfEquityShareCapital': 'Paid-up Capital',\n",
    "    'FaceValueOfEquityShareCapital': 'FV Capital'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert date columns to datetime format\n",
    "date_columns = ['Announcement Date', 'Start of Reporting Period', 'End of Reporting Period']\n",
    "for column in date_columns:\n",
    "    final_df[column] = pd.to_datetime(final_df[column], errors='coerce')\n",
    "\n",
    "# 2. Convert numeric columns to numeric format\n",
    "numeric_columns = ['Revenue', 'EPS', 'Paid-up Capital', 'FV Capital']\n",
    "for column in numeric_columns:\n",
    "    final_df[column] = pd.to_numeric(final_df[column], errors='coerce')\n",
    "\n",
    "# 3. Perform the arithmetic operation\n",
    "final_df['RevenuePerShare'] = final_df['Revenue'] * final_df['FV Capital'] / final_df['Paid-up Capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_2 = final_df[final_df['Report Type'] == 'Consolidated']\n",
    "export = final_df_2[['Announcement Date', 'End of Reporting Period', 'RevenuePerShare', 'EPS']]\n",
    "export = export.rename(columns={'Announcement Date': 'Date', 'End of Reporting Period': 'QuarterEnding'})\n",
    "export.to_csv(f'{stock_symbol}_Fundamental_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
